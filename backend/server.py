import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True,garbage_collection_threshold:0.8,max_split_size_mb:64"

import torch
import asyncio
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, Depends,APIRouter, Form, File, UploadFile, Request
from fastapi.responses import JSONResponse,HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
import uvicorn
from PIL import Image
from typing import Dict, Optional, List
from diffusers import DiffusionPipeline
from diffusers import AutoencoderKLWan, WanVACEPipeline
from diffusers.schedulers.scheduling_unipc_multistep import UniPCMultistepScheduler
import shutil
from langchain import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
import logging, traceback
from pathlib import Path
import anyio, gc

from api import api_video
from api import api_scenario
from api import api_image
from api import api_chr_scenario
from api import api_chr_image
from utils.config import *
import utils.scenario as scenario
from app_core import app

from sqlalchemy import select
from sqlalchemy.orm import Session
import models
from database import engine, Base, SessionLocal
from fastapi.exceptions import RequestValidationError


load_dotenv()
#pip install fastapi uvicorn pydantic langchain langchain-openai langchain-core openai \
#diffusers transformers accelerate safetensors Pillow torch python-dotenv sqlalchemy
# pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, use_safetensors=True, variant="fp16")
# pipe.vae.enable_tiling()
# pipe.vae.enable_slicing()
# pipe.to("cuda")
app.state.pipe = None
app.state.video_pipe=None
app.state.EMIT_LOOP=None
app.state.gpu_sem = anyio.Semaphore(1)  # ë™ì‹œ ìƒì„± ì œí•œ
app.state.active_websockets = {}

def load_pipe():
    pipe = DiffusionPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float16,
        use_safetensors=True,
    )
    pipe.vae.enable_tiling()
    pipe.vae.enable_slicing()
    pipe.to("cuda")

    return pipe

def load_video_pipe():
    model_id = "Wan-AI/Wan2.1-VACE-1.3B-diffusers"
    vae = AutoencoderKLWan.from_pretrained(model_id, subfolder="vae", torch_dtype=torch.float32)
    pipe = WanVACEPipeline.from_pretrained(model_id, vae=vae, torch_dtype=torch.bfloat16)
    flow_shift = 5.0  # 480pë©´ 3.0, 720pë©´ 5.0 ê¶Œì¥
    pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config, flow_shift=flow_shift)
    pipe.vae.enable_tiling()
    pipe.vae.enable_slicing()
    pipe.to("cuda")

    return pipe

def unload_pipe_fully(pipe) -> None:
    try:
        # pipe.to("cpu")ë¥¼ ì¶”ê°€ë¡œ ë„£ì–´ë„ ë˜ì§€ë§Œ 'ì™„ì „ í•´ì œ' ëª©ì ì´ë©´ ìƒëµ ê°€ëŠ¥
        pass
    finally:
        del pipe
        gc.collect()
        torch.cuda.empty_cache()


@app.on_event("startup")
async def init_once():
    if app.state.EMIT_LOOP is None:
        app.state.EMIT_LOOP = asyncio.get_running_loop()

    app.state.model_lock = asyncio.Lock()
    app.state.pipe = None
    app.state.video_pipe = None



def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

Base.metadata.create_all(bind=engine)


#ë°ì´í„° íŒŒì‹±
class init(BaseModel):
    user_id: str



class VideoRequest(BaseModel):
    user_id: str
    project_id:int
    imagePrompt: str
    videoPrompt: str


import mimetypes
# .js íŒŒì¼ì— ëŒ€í•´ MIME íƒ€ì… ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
mimetypes.add_type('application/javascript', '.js')
mimetypes.add_type('text/css', '.css')



app.include_router(api_scenario.router)
app.include_router(api_image.router)
app.include_router(api_video.router)
app.include_router(api_chr_scenario.router)
app.include_router(api_chr_image.router)






# ì˜ˆì™¸ ë””ë²„ê¹… í•¨ìˆ˜
logger = logging.getLogger("app")
def dump_exc(prefix: str, e: Exception):
    tb = "".join(traceback.format_exception(type(e), e, e.__traceback__))
    logger.error("%s: %s\n%s", prefix, repr(e), tb)

#ì›¹ì†Œì¼“ ë“±ë¡ì„ ë¨¼ì €í•´ì•¼í•¨
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    user_id = websocket.query_params.get("user_id")
    
    # ì‚¬ìš©ìë³„ WebSocket ì—°ê²° ì €ì¥
    app.state.active_websockets[user_id] = websocket
    print(f"âœ… WebSocket ì—°ê²°ë¨: {user_id}")
    
    try:
        while True:
            # ì—°ê²° ìœ ì§€ë¥¼ ìœ„í•´ ë©”ì‹œì§€ ëŒ€ê¸°
            data = await websocket.receive_text()
            print(f"ğŸ“¨ ë°›ì€ ë©”ì‹œì§€: {data}")
    except WebSocketDisconnect:
        # ì—°ê²° í•´ì œ ì‹œ ì œê±°
        if user_id in app.state.active_websockets:
            del app.state.active_websockets[user_id]
        print(f"âŒ WebSocket ì—°ê²° í•´ì œ: {user_id}")

#frontend í´ë” mount
app.mount("/frontend", StaticFiles(directory=FRONTEND_DIR), name="frontend")
app.mount("/assets", StaticFiles(directory=ASSETS_DIR), name="assets"
)
# static íŒŒì¼ë“¤ mount
app.mount("/temp", StaticFiles(directory=TEMP_DIR), name="temp")





@app.post('/api/init-user')
def init(user_id:init):
    user_folder = TEMP_DIR / user_id.user_id
    user_folder.mkdir(parents=True,exist_ok=True) 

    # base_dir ì•ˆì˜ í•˜ìœ„ í´ë” ì¤‘ ìˆ«ìë¡œ ëœ ê²ƒë§Œ ì¶”ì¶œ
    num_folders = [int(p.name) for p in user_folder.iterdir() if p.is_dir() and p.name.isdigit()]

    if not num_folders:
        project_id=1
    else:
        project_id = max(num_folders)+1
    return JSONResponse(content={
            "project_id": project_id
        })
    
    





@app.get("/api/saved/{user_id}")
def get_user_texts(user_id: str, db: Session = Depends(get_db)):
    print("ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ ì‹¤í–‰")
    scenario = db.query(models.Scenario).filter(models.Scenario.user_id == user_id).all()
    image = db.query(models.Image).filter(models.Image.user_id==user_id).all()

    data_scenario = [{"id": item.id, "Scenario": item.content} for item in scenario]
    data_image = [{"id":item.id,"image":item.prompt,"model":item.model,"width":item.width,"height":item.height} for item in image]

    return JSONResponse(content={"user_id": user_id, "Scenario": data_scenario, "image":data_image})

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request, exc):
    print("ğŸ” Validation error detail:", exc.errors())   # ì½˜ì†”ì— ìƒì„¸ ì¶œë ¥
    return JSONResponse(status_code=422, content={"detail": exc.errors()})

@app.get('/',response_class=HTMLResponse)
async def serve_frontend():
    print("ë©”ì¸ í˜ì´ì§€ ì‹¤í–‰")
    with open(os.path.join(DIST_DIR, "index.html"), encoding="utf-8") as f:
        html = f.read()
    return HTMLResponse(content=html)

@app.get("/api/projects/{user_id}")
def get_user_projects(user_id: str, db: Session = Depends(get_db)):
    """ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ëª©ë¡ì„ ë°˜í™˜"""
    try:
        print(f"ğŸ“‹ ì‚¬ìš©ì í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ: {user_id}")
        
        # íŠ¹ì • ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ì¡°íšŒ (created_at, updated_at ì œì™¸)
        projects = db.query(
            models.Scenario
        ).filter(
            models.Scenario.user_id == user_id
        ).order_by(models.Scenario.id.desc()).all()
        
        project_list = []
        for project in projects:
            try:
                project_list.append({
                    "project_id": project.project_id,
                    "title": project.user_topic_input or "ì œëª© ì—†ìŒ",
                    "date": "ìµœê·¼"  # ì„ì‹œë¡œ ê³ ì •ê°’ ì‚¬ìš©
                })
            except Exception as e:
                print(f"âŒ í”„ë¡œì íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        print(f"âœ… ì´ {len(project_list)}ê°œ í”„ë¡œì íŠ¸ ì¡°íšŒë¨")
        
        return JSONResponse(content={
            "user_id": user_id,
            "projects": project_list
        })
        
    except Exception as e:
        print(f"âŒ í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        return JSONResponse(content={
            "user_id": user_id,
            "projects": [],
            "error": str(e)
        }, status_code=500)
    

@app.get("/api/project/{user_id}/{project_id}")
def get_project(user_id:str,project_id: int, db: Session = Depends(get_db)):
    # í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´
    scenario_db = (
    db.query(models.Scenario)
      .filter(
          models.Scenario.user_id == user_id,
          models.Scenario.project_id == project_id,
      )
      .order_by(models.Scenario.id.desc())
      .first())
    
    if not scenario_db:
        raise HTTPException(status_code=404, detail="Project not found")

    # ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ê°€ì ¸ì˜¤ê¸°
    image_db = (
    db.query(models.Image)
      .filter(
          models.Image.user_id == user_id,
          models.Image.project_id == project_id,
      ).first())
    
    kor_contents=scenario.split_contents(scenario.translate_eng2kor(scenario_db.contents))
    print(scenario_db.contents)
    print(kor_contents)
    return {
        "title": scenario_db.user_topic_input,
        "topic": scenario.translate_eng2kor(scenario_db.topic),
        "description" : scenario.translate_eng2kor(scenario_db.description),
        "contents":kor_contents,
        "keyframe_prompt": image_db.image_prompt,
        "video_prompt" : image_db.video_prompt
    }

#fallbackí•¨ìˆ˜ : vueì—ì„œ ì²˜ë¦¬í•  ê²½ë¡œì˜ ìš”ì²­ì€ index.html ë³´ëƒ„
@app.get("/{full_path:path}", response_class=HTMLResponse)
async def fallback(full_path: str):
    print("ğŸ”„ í´ë°±í•¨ìˆ˜ ì‹¤í–‰")
    if full_path.startswith("ws"):
        return HTMLResponse(status_code=404, content="ì›¹ì†Œì¼“ì€ FastAPIê°€ ì²˜ë¦¬í•¨")
    return FileResponse(os.path.join(DIST_DIR, "index.html"))
# @app.get("/")
# async def root():
#     return {"message": "Hello Backend"}

if __name__ == "__main__":
    uvicorn.run(
        "server:app",          # ëª¨ë“ˆ:ë³€ìˆ˜
        host="0.0.0.0",        # ì™¸ë¶€ ì ‘ì† í—ˆìš©
        port=8080,             # í¬íŠ¸ ë²ˆí˜¸
        reload=False            # ì½”ë“œ ìˆ˜ì • ì‹œ ìë™ reload
    )